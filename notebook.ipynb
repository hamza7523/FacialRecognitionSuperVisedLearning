{"cells":[{"source":"![Facial Recognition](facialrecognition.jpg)","metadata":{},"id":"88c639dc-bfcd-449e-bddd-55f8bd551dd5","cell_type":"markdown"},{"source":"You are a member of an elite group of data scientists, specialising in advanced facial recognition technology, this firm is dedicated to identifying and safeguarding prominent individuals from various spheresâ€”ranging from entertainment and sports to politics and philanthropy. The team's mission is to deploy AI-driven solutions that can accurately distinguish between images of notable personalities and the general populace, enhancing the personal security of such high-profile individuals. You're to focus on Arnold Schwarzenegger, a figure whose accomplishments span from bodybuilding champion to Hollywood icon, and from philanthropist to the Governor of California. ","metadata":{},"id":"0fd04b96-d360-411c-8b17-a10382c97d29","cell_type":"markdown"},{"source":"### **The Data**\nThe `data/lfw_arnie_nonarnie.csv` dataset contains processed facial image data derived from the \"Labeled Faces in the Wild\" (LFW) dataset, focusing specifically on images of Arnold Schwarzenegger and other individuals not identified as him. This dataset has been prepared to aid in the development and evaluation of facial recognition models. There are 40 images of Arnold Schwarzenegger and 150 of other people.\n\n| Column Name | Description |\n|-------------|-------------|\n| PC1, PC2, ... PCN | Principal components from PCA, capturing key image features. |\n| Label | Binary indicator: `1` for Arnold Schwarzenegger, `0` for others. |","metadata":{},"id":"be124832-8192-4f93-b487-247c3d03d23b","cell_type":"markdown"},{"source":"# Import required libraries\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read the CSV file \ndf = pd.read_csv(\"data/lfw_arnie_nonarnie.csv\")\n\n# Seperate the predictor and class label\nX = df.drop('Label', axis=1)\ny = df['Label'] \n\n# Split the data into training and testing sets using stratify to balance the class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)","metadata":{"executionCancelledAt":null,"executionTime":27,"lastExecutedAt":1738531977259,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read the CSV file \ndf = pd.read_csv(\"data/lfw_arnie_nonarnie.csv\")\n\n# Seperate the predictor and class label\nX = df.drop('Label', axis=1)\ny = df['Label'] \n\n# Split the data into training and testing sets using stratify to balance the class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"},"id":"2e0be28b-29dd-49bd-8e8b-f3cb828a5065","cell_type":"code","execution_count":115,"outputs":[]},{"source":"print(X_train);\n","metadata":{"executionCancelledAt":null,"executionTime":76,"lastExecutedAt":1738531977336,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(X_train);\n","outputsMetadata":{"0":{"height":311,"type":"stream"}}},"id":"f09a4e74-4a69-4dfc-8a54-f285653796d9","cell_type":"code","execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":"            0         1         2  ...       147       148       149\n63  -0.174255 -2.970224  3.230451  ... -0.232865 -0.202193  0.221698\n20  -3.533020  0.858683  1.185077  ... -0.023084  0.023557 -0.005008\n125 -5.771363 -2.005809  1.249855  ... -0.049232  0.067747 -0.169667\n130  9.150897 -7.013354  2.596765  ... -0.001627 -0.044008  0.101841\n41   1.872624 -0.253442  2.596265  ... -0.093455  0.008534  0.185321\n..        ...       ...       ...  ...       ...       ...       ...\n153 -1.124056  0.537134  2.017247  ... -0.176542 -0.036645  0.027890\n79  -3.552765  1.089497 -2.182357  ... -0.169197  0.153629 -0.130576\n157 -1.908888  0.837640  2.345791  ... -0.376907  0.153506  0.278081\n64  -1.400702  1.999302  4.259822  ... -0.138655 -0.241056 -0.108794\n137  8.415617 -2.587975 -2.370433  ... -0.150624 -0.061419 -0.105073\n\n[152 rows x 150 columns]\n"}]},{"source":"print(y_train)\nfrom sklearn.linear_model import LogisticRegression;\n","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1738531977388,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(y_train)\nfrom sklearn.linear_model import LogisticRegression;\n","outputsMetadata":{"0":{"height":269,"type":"stream"}}},"cell_type":"code","id":"e2152c6a-e52e-49e6-becf-5f01f665bde6","outputs":[{"output_type":"stream","name":"stdout","text":"63     0\n20     1\n125    0\n130    0\n41     0\n      ..\n153    0\n79     0\n157    0\n64     0\n137    0\nName: Label, Length: 152, dtype: int64\n"}],"execution_count":117},{"source":"logisticRegression = LogisticRegression();\nlogisticRegression.fit(X_train,y_train);","metadata":{"executionCancelledAt":null,"executionTime":243,"lastExecutedAt":1738531977631,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"logisticRegression = LogisticRegression();\nlogisticRegression.fit(X_train,y_train);"},"cell_type":"code","id":"ac8f0bd5-1b1b-4c50-9e54-079b2aa9a53f","outputs":[],"execution_count":118},{"source":"from sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n}\n\n# Create a GridSearchCV object\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n\n# Fit the model\ngrid_search.fit(X_train, y_train)\n\n# Get the best estimator\nbest_logistic_regression = grid_search.best_estimator_\n\n# Predict using the best estimator\npreds = best_logistic_regression.predict(X_test)\n\n# Print the classification report\nfrom sklearn.metrics import classification_report\nprint(f\"{best_logistic_regression} Results:\\n{classification_report(y_test, preds)}\", sep=\"\\n\\n\")","metadata":{"executionCancelledAt":null,"executionTime":6206,"lastExecutedAt":1738531983837,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n}\n\n# Create a GridSearchCV object\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n\n# Fit the model\ngrid_search.fit(X_train, y_train)\n\n# Get the best estimator\nbest_logistic_regression = grid_search.best_estimator_\n\n# Predict using the best estimator\npreds = best_logistic_regression.predict(X_test)\n\n# Print the classification report\nfrom sklearn.metrics import classification_report\nprint(f\"{best_logistic_regression} Results:\\n{classification_report(y_test, preds)}\", sep=\"\\n\\n\")","outputsMetadata":{"0":{"height":227,"type":"stream"}}},"cell_type":"code","id":"e32ce10d-5136-4331-afad-f6c7c3d2475e","outputs":[{"output_type":"stream","name":"stdout","text":"LogisticRegression(C=0.1, solver='newton-cg') Results:\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94        30\n           1       0.83      0.62      0.71         8\n\n    accuracy                           0.89        38\n   macro avg       0.87      0.80      0.82        38\nweighted avg       0.89      0.89      0.89        38\n\n"}],"execution_count":119},{"source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n# Define the parameter grid correctly for DecisionTreeClassifier\nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ntree = DecisionTreeClassifier()\ngridsearch1 = GridSearchCV(tree, param_grid, cv=5, scoring=\"accuracy\")\ngridsearch1.fit(X_train, y_train)\nbestDecisionTree = gridsearch1.best_estimator_\npredTree = bestDecisionTree.predict(X_test)\nprint(f\"{bestDecisionTree} Results:\\n{classification_report(y_test, predTree)}\", sep=\"\\n\\n\")","metadata":{"executionCancelledAt":null,"executionTime":3803,"lastExecutedAt":1738531987640,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n# Define the parameter grid correctly for DecisionTreeClassifier\nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ntree = DecisionTreeClassifier()\ngridsearch1 = GridSearchCV(tree, param_grid, cv=5, scoring=\"accuracy\")\ngridsearch1.fit(X_train, y_train)\nbestDecisionTree = gridsearch1.best_estimator_\npredTree = bestDecisionTree.predict(X_test)\nprint(f\"{bestDecisionTree} Results:\\n{classification_report(y_test, predTree)}\", sep=\"\\n\\n\")","outputsMetadata":{"0":{"height":227,"type":"stream"}}},"cell_type":"code","id":"70dfef6e-9342-4a4b-ad59-e99d2582f6ad","outputs":[{"output_type":"stream","name":"stdout","text":"DecisionTreeClassifier() Results:\n              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80        30\n           1       0.25      0.25      0.25         8\n\n    accuracy                           0.68        38\n   macro avg       0.53      0.53      0.53        38\nweighted avg       0.68      0.68      0.68        38\n\n"}],"execution_count":120},{"source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Initialize models dictionary\nmodels = {\n    'Logistic Regression': Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', LogisticRegression())\n    ]),\n    'Decision Tree': Pipeline([\n        ('classifier', DecisionTreeClassifier())\n    ]),\n    'KNeighbors': Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', KNeighborsClassifier())\n    ])\n}\n\n# Initialize variables to store the best model information\nbest_model_name = None\nbest_model_info = None\nbest_model_cv_score = 0\n\n# Perform cross-validation and determine the best model\nfor model_name, model_pipeline in models.items():\n    cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n    mean_cv_score = cv_scores.mean()\n    \n    if mean_cv_score > best_model_cv_score:\n        best_model_name = model_name\n        best_model_info = model_pipeline.get_params()\n        best_model_cv_score = mean_cv_score\n\n# Fit the best model on the training data\nbest_model = models[best_model_name]\nbest_model.fit(X_train, y_train)\n\n# Predict on the test set\ntest_preds = best_model.predict(X_test)\n\n# Evaluate the best model\naccuracy = accuracy_score(y_test, test_preds)\nprecision = precision_score(y_test, test_preds, average='weighted')\nrecall = recall_score(y_test, test_preds, average='weighted')\nf1 = f1_score(y_test, test_preds, average='weighted')\n\n# Store the best accuracy score\nscore = accuracy\n\n# Output the results\nbest_model_name, best_model_info, best_model_cv_score, accuracy, precision, recall, f1, score","metadata":{"executionCancelledAt":null,"executionTime":993,"lastExecutedAt":1738531988634,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Initialize models dictionary\nmodels = {\n    'Logistic Regression': Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', LogisticRegression())\n    ]),\n    'Decision Tree': Pipeline([\n        ('classifier', DecisionTreeClassifier())\n    ]),\n    'KNeighbors': Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', KNeighborsClassifier())\n    ])\n}\n\n# Initialize variables to store the best model information\nbest_model_name = None\nbest_model_info = None\nbest_model_cv_score = 0\n\n# Perform cross-validation and determine the best model\nfor model_name, model_pipeline in models.items():\n    cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n    mean_cv_score = cv_scores.mean()\n    \n    if mean_cv_score > best_model_cv_score:\n        best_model_name = model_name\n        best_model_info = model_pipeline.get_params()\n        best_model_cv_score = mean_cv_score\n\n# Fit the best model on the training data\nbest_model = models[best_model_name]\nbest_model.fit(X_train, y_train)\n\n# Predict on the test set\ntest_preds = best_model.predict(X_test)\n\n# Evaluate the best model\naccuracy = accuracy_score(y_test, test_preds)\nprecision = precision_score(y_test, test_preds, average='weighted')\nrecall = recall_score(y_test, test_preds, average='weighted')\nf1 = f1_score(y_test, test_preds, average='weighted')\n\n# Store the best accuracy score\nscore = accuracy\n\n# Output the results\nbest_model_name, best_model_info, best_model_cv_score, accuracy, precision, recall, f1, score","outputsMetadata":{"0":{"height":416,"type":"stream"}}},"cell_type":"code","id":"400483a5-6f7a-4505-9027-28f2fde57970","outputs":[{"output_type":"execute_result","data":{"text/plain":"('Logistic Regression',\n {'memory': None,\n  'steps': [('scaler', StandardScaler()),\n   ('classifier', LogisticRegression())],\n  'verbose': False,\n  'scaler': StandardScaler(),\n  'classifier': LogisticRegression(),\n  'scaler__copy': True,\n  'scaler__with_mean': True,\n  'scaler__with_std': True,\n  'classifier__C': 1.0,\n  'classifier__class_weight': None,\n  'classifier__dual': False,\n  'classifier__fit_intercept': True,\n  'classifier__intercept_scaling': 1,\n  'classifier__l1_ratio': None,\n  'classifier__max_iter': 100,\n  'classifier__multi_class': 'auto',\n  'classifier__n_jobs': None,\n  'classifier__penalty': 'l2',\n  'classifier__random_state': None,\n  'classifier__solver': 'lbfgs',\n  'classifier__tol': 0.0001,\n  'classifier__verbose': 0,\n  'classifier__warm_start': False},\n 0.8221505376344087,\n 0.8157894736842105,\n 0.8506401137980085,\n 0.8157894736842105,\n 0.7537749847254953,\n 0.8157894736842105)"},"metadata":{},"execution_count":121}],"execution_count":121},{"source":"# Assuming y_true and y_pred are defined somewhere in the notebook\n# If not, define them here for the sake of completeness\n# y_true = ...\n# y_pred = ...\n\n# Save the best model's parameters as 'best_model_info'\nbest_model_info = {\n    'accuracy': knn_accuracy,\n    'precision': knn_precision,\n    'recall': knn_recall,\n    'f1': knn_f1\n\n}\n\n# Save the best model's cross-validation score as 'best_model_cv_score'\nbest_model_cv_score = best_model_cv_scores\n\n# Display the best model information\nbest_model_info","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1738531988684,"lastExecutedByKernel":"32f13729-a6db-4641-adb4-fead22507e61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Assuming y_true and y_pred are defined somewhere in the notebook\n# If not, define them here for the sake of completeness\n# y_true = ...\n# y_pred = ...\n\n# Save the best model's parameters as 'best_model_info'\nbest_model_info = {\n    'accuracy': knn_accuracy,\n    'precision': knn_precision,\n    'recall': knn_recall,\n    'f1': knn_f1\n\n}\n\n# Save the best model's cross-validation score as 'best_model_cv_score'\nbest_model_cv_score = best_model_cv_scores\n\n# Display the best model information\nbest_model_info"},"cell_type":"code","id":"1bd470f2-5d08-4c97-ac2c-0cff041f7d1d","outputs":[{"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.7368421052631579,\n 'precision': 0.6795665634674922,\n 'recall': 0.7368421052631579,\n 'f1': 0.7012061403508771}"},"metadata":{},"execution_count":122}],"execution_count":122}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}